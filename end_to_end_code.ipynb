{"cells":[{"cell_type":"code","source":["import pandas as pd\n\n#Read the Wteam file\nwteamDF = spark.read.csv(\"/FileStore/tables/WTeams.csv\", header=True, inferSchema= True)\nlteamDF = spark.read.csv(\"/FileStore/tables/WTeams.csv\", header=True, inferSchema= True)"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["#Convert into Pandas DF from sql.dataframe\nwteamDF = wteamDF.toPandas()\nlteamDF = lteamDF.toPandas()\n#Rename the column to WTeamName\n\nwteamDF.columns = ['WTeamID', 'WTeamName']\nlteamDF.columns = ['LTeamID', 'LTeamName']\n"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["#Read the RegularSeasons CSV File\nregularSeasonsDF = spark.read.csv(\"/FileStore/tables/WRegularSeasonCompactResults.csv\", header=True, inferSchema= True)\n"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["regularSeasonsDF = regularSeasonsDF.toPandas()\n"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["lteamDF[:2]"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["#merge why??\nx = regularSeasonsDF.merge(wteamDF, on='WTeamID', how='left')"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["x[:2]"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["y=x.merge(lteamDF,on='LTeamID',how='left') "],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["#To check if all the entries are non-null\ny.isnull().sum()"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["final_regularSeasonsDF = y"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["final_regularSeasonsDF[:3]"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["#Merging the Seeds and Slots\nseedsDF = spark.read.csv(\"/FileStore/tables/WNCAATourneySeeds.csv\", header=True, inferSchema= True)\n\nslotsDF = spark.read.csv(\"/FileStore/tables/WNCAATourneySlots.csv\", header=True, inferSchema=True)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["slotsDF = slotsDF.toPandas()\n\n\n"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["seedsDF = seedsDF.toPandas()\n\nseedsDF.head(5)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["#Concatenate to replicate the rows for 63 matches in each season\nslotsDF = pd.concat([slotsDF]*20, ignore_index=True) ###dbt\nlen(slotsDF['Slot']) #sbt"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["seedsDF[1279:]"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["allyears = seedsDF['Season']\n\nslotsDF['Season'] = pd.Series(allyears, dtype='int32')\n  "],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["slotsDF[:70]"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["len(seedsDF['Season'])"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["slotsDF[1260:]"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["#for i in range(0, len(seedsDF['Season'])):\n  #if(seedsDF['Seed'])"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["CompactDF = spark.read.csv(\"/FileStore/tables/WNCAATourneyCompactResults.csv\", header=True, inferSchema= True)\n\nNewseedsDF=seedsDF\n\nCompactDF.show()"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["#DICTIONARY -team id,season as key and seed as value\n\nseedsdict={}\nfor row in NewseedsDF.iterrows():\n  seedsdict[(row[1][\"Season\"], row[1][\"TeamID\"])] = row[1][\"Seed\"]\n"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["CompactDF = CompactDF.toPandas()"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["temp_wCol = []\ntemp_lCol = []\nfor row in CompactDF.iterrows():\n  year = row[1]['Season']\n  wteamid = row[1]['WTeamID']\n  lteamid = row[1]['LTeamID']\n  temp_wCol.append(seedsdict[(year,wteamid)])\n  temp_lCol.append(seedsdict[(year,lteamid)])\n  "],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["CompactDF['WSeed'] = temp_wCol\nCompactDF['LSeed'] = temp_lCol\n\nCompactDF.head(10)"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["weights_dict = {}\nj = 1\nfor i in range(16,0,-1):\n  weights_dict[j] = i\n  j+=1\n  print weights_dict  \n#temp_val = abs(weights_dict[int(wseed[1:])] - weights_dict[int(lseed[1:])])"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["temp_win = []\nwseed_num = []\nlseed_num = []\ndiff_seed = []\nloc_col = []\ndiff_score = []\n\nfor row in CompactDF.iterrows():\n  \n  team_1 = row[1]['WTeamID']\n  team_2 = row[1]['LTeamID']\n  loc_val = row[1]['WLoc']\n  wseed = row[1]['WSeed']\n  lseed =row[1]['LSeed']\n#ask why 1 & 0 for temp_win  \n  if(team_1<team_2):\n    temp_win.append(1)\n  else:\n    temp_win.append(0)\n    \n  if(loc_val == 'H'):\n    loc_col.append(3)\n  elif(loc_val == 'N'):\n    loc_col.append(2)\n  elif(loc_val=='A'):\n    loc_col.append(1)\n  \n  #print wseed[1:]   \n  temp_val = abs(weights_dict[int(wseed[1:])] - weights_dict[int(lseed[1:])])\n  #temp_val = abs(weights_dict[int(wseed[1:])] - weights_dict[int(lseed[1:])])\n  diff_seed.append(temp_val)\n  \n  diff_score.append(abs(row[1]['WScore'] - row[1]['LScore']))\n  "],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["CompactDF['WLProb'] = temp_win"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["CompactDF['Seed_Diff'] = diff_seed\n"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["CompactDF['Loc'] = loc_col"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":["CompactDF['Score_Diff'] = diff_score"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["CompactDF[:10]"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["# Functionality for computing features\nfrom pyspark.ml import feature\n# Functionality for regression\nfrom pyspark.ml import regression\n# Funcionality for classification\nfrom pyspark.ml import classification\n# Object for creating sequences of transformations\nfrom pyspark.ml import Pipeline"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["\nfeatureCols = [\"DayNum\", \"WTeamID\", \"LTeamID\", \"Score_Diff\", \"Loc\", \"Seed_Diff\", \"NumOT\"]\n#set the input and output column names**\nassembler = feature.VectorAssembler(inputCols = featureCols, outputCol = \"features\")\n#return a dataframe with all of the  feature columns in  a vector column**\n"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["# Split dataset randomly into Training and Test sets. Set seed for reproducibility\nimport numpy as np\ntrainingData, validationData, testData = np.split(CompactDF, [int(0.6*len(CompactDF)), int(0.9*len(CompactDF))])"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["from pyspark.sql import SQLContext\nsqlCtx = SQLContext(sc)\nsql_compactDF = sqlCtx.createDataFrame(CompactDF)\n\nsql_compactDF= sql_compactDF.withColumnRenamed(\"WLProb\", \"label\")\nsql_compactDF.show()"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"code","source":["trainingData, validationData, testData = sql_compactDF.randomSplit([0.6,0.3,0.1])"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"code","source":["trainingData.show()"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"code","source":["from pyspark.ml.feature import StringIndexer\n# Convert target into numerical categories\nlabelIndexer = StringIndexer(inputCol=\"WLProb\", outputCol=\"label\")\n"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"code","source":["sql_compactDF= sql_compactDF.withColumnRenamed(\"WLProb\", \"label\")\nsql_compactDF.show()"],"metadata":{},"outputs":[],"execution_count":43},{"cell_type":"code","source":["from pyspark.ml.classification import LogisticRegression\n# Train a Logistic Regression model\nlogisticReg = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n\n# Chain labelIndexer, vecAssembler and NBmodel in a \npipeline = Pipeline(stages=[ assembler, logisticReg])\n\n# Run stages in pipeline and train model\nmodel = pipeline.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":44},{"cell_type":"code","source":["predictions = model.transform(validationData)"],"metadata":{},"outputs":[],"execution_count":45},{"cell_type":"code","source":["sql_compactDF= sql_compactDF.withColumnRenamed(\"WLProb\", \"label\")"],"metadata":{},"outputs":[],"execution_count":46},{"cell_type":"code","source":["test_prediction = model.transform(testData)\ntest_prediction.show()"],"metadata":{},"outputs":[],"execution_count":47},{"cell_type":"code","source":["display(test_prediction.select(\"label\", \"prediction\", \"probability\"))\n"],"metadata":{},"outputs":[],"execution_count":48},{"cell_type":"code","source":["from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\nevaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\"\n                                              )\naccuracy = evaluator.evaluate(test_prediction)\nprint \"Model Accuracy: \", accuracy"],"metadata":{},"outputs":[],"execution_count":49},{"cell_type":"code","source":["evaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":50},{"cell_type":"code","source":["####APPLYING RANDOM FOREST#####################"],"metadata":{},"outputs":[],"execution_count":51},{"cell_type":"code","source":["rdd_compactDF=sql_compactDF.rdd\nrdd_compactDF.take(2)"],"metadata":{},"outputs":[],"execution_count":52},{"cell_type":"code","source":["CompactDF = spark.read.csv(\"/FileStore/tables/WNCAATourneyCompactResults.csv\", header=True, inferSchema= True)"],"metadata":{},"outputs":[],"execution_count":53},{"cell_type":"code","source":["type(sql_compactDF)\nsql_compactDF.show()"],"metadata":{},"outputs":[],"execution_count":54},{"cell_type":"code","source":["from pyspark.sql import SQLContext\nsqlCtx = SQLContext(sc)\nsql_compactDF = sqlCtx.createDataFrame(CompactDF)\n\nsql_compactDF= sql_compactDF.withColumnRenamed(\"WLProb\", \"label\")\n#sql_compactDF.show()"],"metadata":{},"outputs":[],"execution_count":55},{"cell_type":"code","source":["CompactDF[:10]"],"metadata":{},"outputs":[],"execution_count":56},{"cell_type":"code","source":["sql_compactDF"],"metadata":{},"outputs":[],"execution_count":57},{"cell_type":"code","source":["Rand_DF=CompactDF\nRand_DF=Rand_DF[['Season','DayNum','WTeamID','WScore','LTeamID','LScore','NumOT','WSeed','LSeed','WLProb','Seed_Diff','Score_Diff','Loc']]\nRand_DF[:4]"],"metadata":{},"outputs":[],"execution_count":58},{"cell_type":"code","source":["\n###One-Hot Encoding\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\ncategoricalColumns = [\"Loc\"]\nstages = [] # stages in our Pipeline\nfor categoricalCol in categoricalColumns:\n  # Category Indexing with StringIndexer\n  stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol+\"Index\")\n  # Use OneHotEncoder to convert categorical variables into binary SparseVectors\n  encoder = OneHotEncoder(inputCol=categoricalCol+\"Index\", outputCol=categoricalCol+\"classVec\")\n  # Add stages.  These are not run here, but will run all at once later on.\n  stages += [stringIndexer, encoder]#, but will run all at once later on.\n  #stages += [stringIndexer, encoder]"],"metadata":{},"outputs":[],"execution_count":59},{"cell_type":"code","source":["cols = Rand_DF.columns\ncols"],"metadata":{},"outputs":[],"execution_count":60},{"cell_type":"code","source":["#Convert label into label indices using the StringIndexer\nlabel_stringIdx = StringIndexer(inputCol = \"WLProb\", outputCol = \"label\")\nstages += [label_stringIdx]"],"metadata":{},"outputs":[],"execution_count":61},{"cell_type":"code","source":["featureCols = [\"DayNum\", \"WTeamID\", \"LTeamID\", \"Score_Diff\", \"Seed_Diff\", \"NumOT\",\"Loc\"]\n#assemblerInputs = map(lambda c: c, categoricalColumns) + featureCols\n#assemblerInputs = map(lambda c: c + \"classVec\", categoricalColumns) + featureCols\nassembler = VectorAssembler(inputCols=featureCols, outputCol=\"features\")\nstages += [assembler]"],"metadata":{},"outputs":[],"execution_count":62},{"cell_type":"code","source":["# Create a Pipeline.\npipeline = Pipeline(stages=stages)\n# Run the feature transformations.\n#  - fit() computes feature statistics as needed.\n#  - transform() actually transforms the features.\n"],"metadata":{},"outputs":[],"execution_count":63},{"cell_type":"code","source":["from pyspark.sql import SQLContext\nsqlCtx = SQLContext(sc)\nsql_RandDF = sqlCtx.createDataFrame(Rand_DF)\nsql_RandDF.take(2)\n#sql_compactDF= sql_compactDF.withColumnRenamed(\"WLProb\", \"label\")"],"metadata":{},"outputs":[],"execution_count":64},{"cell_type":"code","source":["pipelineModel = pipeline.fit(sql_RandDF)\n#from pyspark.sql import SQLContext\n#sqlCtx = SQLContext(sc)\n#sql_compactDF = sqlCtx.createDataFrame(CompactDF)\n\n#sql_compactDF= sql_compactDF.withColumnRenamed(\"WLProb\", \"label\")\ndataset = pipelineModel.transform(sql_RandDF)\ndataset.show()"],"metadata":{},"outputs":[],"execution_count":65},{"cell_type":"code","source":["# Keep relevant columns\n#selectedcols = [\"label\", \"features\"] + cols\n#dataset = dataset.select(selectedcols)\n#display(dataset)"],"metadata":{},"outputs":[],"execution_count":66},{"cell_type":"code","source":["### Randomly split data into training and test sets. set seed for reproducibility\n(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\nprint trainingData.count()\nprint testData.count()"],"metadata":{},"outputs":[],"execution_count":67},{"cell_type":"code","source":["trainingData.show()"],"metadata":{},"outputs":[],"execution_count":68},{"cell_type":"code","source":["from pyspark.sql import functions as fn\ntestData.select(fn.avg('label')).show()"],"metadata":{},"outputs":[],"execution_count":69},{"cell_type":"code","source":["from pyspark.ml.classification import RandomForestClassifier\n\n# Create an initial RandomForest model.\nrf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n\n# Train model with Training Data\nrfModel = rf.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":70},{"cell_type":"code","source":["Rand_DF=CompactDF\nRand_DF=Rand_DF[['Season','DayNum','WTeamID','WScore','LTeamID','LScore','NumOT','WSeed','LSeed','WLProb','Seed_Diff','Score_Diff','Loc']]\nRand_DF[:4]"],"metadata":{},"outputs":[],"execution_count":71},{"cell_type":"code","source":["# Make predictions on test data using the Transformer.transform() method.\npredictions = rfModel.transform(testData)"],"metadata":{},"outputs":[],"execution_count":72},{"cell_type":"code","source":["predictions.printSchema()\n"],"metadata":{},"outputs":[],"execution_count":73},{"cell_type":"code","source":["selected = predictions.select(\"WLProb\",\"label\", \"prediction\", \"probability\", \"WTeamID\")\ndisplay(selected)"],"metadata":{},"outputs":[],"execution_count":74},{"cell_type":"code","source":["#We will evaluate our Random Forest model with BinaryClassificationEvaluator."],"metadata":{},"outputs":[],"execution_count":75},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n# Evaluate model\nevaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction')\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":76},{"cell_type":"code","source":["#Now we will try tuning the model with the ParamGridBuilder and the CrossValidator.\n\n#As we indicate 3 values for maxDepth, 2 values for maxBin, and 2 values for numTrees, this grid will have 3 x 2 x 2 = 12 parameter settings for CrossValidator to choose from. We will create a 5-fold CrossValidator."],"metadata":{},"outputs":[],"execution_count":77},{"cell_type":"code","source":["# Create ParamGrid for Cross Validation\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\nparamGrid = (ParamGridBuilder()\n             .addGrid(rf.maxDepth, [2, 4, 6])\n             .addGrid(rf.maxBins, [20, 60])\n             .addGrid(rf.numTrees, [5, 20])\n             .build())"],"metadata":{},"outputs":[],"execution_count":78},{"cell_type":"code","source":["# Create 5-fold CrossValidator\ncv = CrossValidator(estimator=rf, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n\n# Run cross validations.  This can take about 6 minutes since it is training over 20 trees!\ncvModel = cv.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":79},{"cell_type":"code","source":["# Use test set here so we can measure the accuracy of our model on new data\npredictions = cvModel.transform(testData)"],"metadata":{},"outputs":[],"execution_count":80},{"cell_type":"code","source":["# cvModel uses the best model found from the Cross Validation\n# Evaluate best model\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":81},{"cell_type":"code","source":["bestModel = cvModel.bestModel"],"metadata":{},"outputs":[],"execution_count":82},{"cell_type":"code","source":["# Generate predictions for entire dataset\nfinalPredictions = bestModel.transform(dataset)"],"metadata":{},"outputs":[],"execution_count":83},{"cell_type":"code","source":["# Evaluate best model\nevaluator.evaluate(finalPredictions)"],"metadata":{},"outputs":[],"execution_count":84},{"cell_type":"code","source":["finalPredictions.createOrReplaceTempView(\"finalPredictions\")"],"metadata":{},"outputs":[],"execution_count":85}],"metadata":{"name":"project_2","notebookId":795262472997413},"nbformat":4,"nbformat_minor":0}
